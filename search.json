[{"categories":null,"content":"Kafka Consumer API 独立消费者 Standalone Consumer 每次都会从第1条消息开始消费，一直到消费完全部小新，不会记录offset，妥妥的重复消费，需要借助 OffsetManager 来完成。\n未使用OffsetManager的StandaloneConsumer 单分区消费 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 func SinglePartition(topic string) { config := sarama.NewConfig() host := \"x.x.x.x:xx\" consumer, err := sarama.NewConsumer([]string{host}, config) if err != nil { log.Fatal(\"NewConsumer err:\", err) } defer consumer.Close() //独立消费者中 sarama.OffsetOldest 会从最旧的消息开始消费，即每次重启 consumer后 都会把该topic下的所有消息都消费一次 partitionConsumer, err := consumer.ConsumePartition(topic, 0, sarama.OffsetOldest) if err != nil { log.Fatal(\"ConsumePartition err:\", err) } defer partitionConsumer.Close() //会一直阻塞在这里 for message := range partitionConsumer.Messages() { log.Printf(\"[Consumer] partitionid:%d; offset:%d, value:%s\\n\", message.Partition, message.Offset, string(message.Value)) } } 多分区消费 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 func Partitions(topic string) { config := sarama.NewConfig() host := \"x.x.x.x:xx\" consumer, err := sarama.NewConsumer([]string{host}, config) if err != nil { log.Fatal(\"NewConsumer err: err\") } defer consumer.Close() //先查询 topic有多少分区 partitions, err := consumer.Partitions(topic) if err != nil { log.Fatal(\"Partitions err:\", err) } var wg sync.WaitGroup wg.Add(len(partitions)) //然后每个分区开一个goroutine来消费 for _, partitionId := range partitions { go consumeByPartition(consumer, topic, partitionId, \u0026wg) } wg.Wait() } func consumeByPartition(consumer sarama.Consumer, topic string, partitionId int32, wg *sync.WaitGroup) { defer wg.Done() partitionConsumer, err := consumer.ConsumePartition(topic, partitionId, sarama.OffsetOldest) if err != nil { log.Fatal(\"ConsumePartition err:\", err) } defer partitionConsumer.Close() for message := range partitionConsumer.Messages() { log.Printf(\"[Consumer] partitionid:%d; offset:%d, value:%s\\n\", message.Partition, message.Offset, string(message.Value)) } } 反复运行上面的Demo会发现，每次都会从第1条消息开始消费，一直到消费完 全部消息。 这不是妥妥的重复消费吗？ Kafka和其他MQ最大的区别在于Kafka中的消息再消费后不会被删除，而是会一直保留，直到过期。 为了防止每次重启消费者都从第1条消息开始消费，我们需要再消费消息后将offset提交给Kafka。这样重启后就可以接着上次的Offset继续消费了\n在独立消费者中没有实现提交Offset的功能，所以需要借助OffsetManager来完成\n使用OffsetManager的StandaloneConsumer 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 func OffsetManager(topic string) { config := sarama.NewConfig() host := \"x.x.x.x:xx\" //配置开启自动提交offset， 这样samara库会自动把最新的offset提交给kafka config.Consumer.Offsets.AutoCommit.Enable = true //开启自动commit offset config.Consumer.Offsets.AutoCommit.Interval = 1 * time.Second //自动 commit时间间隔 client, err := sarama.NewClient([]string{host}, config) if err != nil { log.Fatal(\"NewClient err:\", err) } defer client.Close() consumer, err := sarama.NewConsumerFromClient(client) if err != nil { log.Println(\"NewConsumeFromClient err:\", err) } defer consumer.Close() // 先查询该 topic 有多少分区 partitions, err := consumer.Partitions(topic) if err != nil { log.Fatal(\"Partitions err: \", err) } var wg sync.WaitGroup wg.Add(len(partitions)) for _, partitionId := range partitions { go ConsumeByOffsetManager(client, partitionId, \u0026wg, consumer) } wg.Wait() } func ConsumeByOffsetManager(client sarama.Client, i int32, wg *sync.WaitGroup, consumer sarama.Consumer) { defer wg.Done() //offsetManager用于管理每个ConsumerGroup的offset //根据groupId来区分不同的consume, 注意：每次提交的offset信息也是和groupId关联的 offsetManager, err := sarama.NewOffsetManagerFromClient(\"myGroupId\", client) //偏移管理器 if err != nil { log.Println(\"NewOffsetManagerFromClient err:\", err) } defer offsetManager.Close() partitionOffsetManager, err := offsetManager.ManagePartition(\"topic_name\", i) //对应分区的偏移量管理管理器 if err != nil { log.Println(\"ManagerPartition err:\", err) } defer partitionOffsetManager.Close() //defer在程序结束后再commit一次，防止自动提交间隔之间的信息被丢掉 defer offsetManager.Commit() //根据kafka中记录的上次消费的offset开始+1的位置接着消费 nextOffset, _ := partitionOffsetManager.NextOffset() fmt.Println(\"nextOffset:\", nextOffset) pc, err := consumer.ConsumePartition(\"topic_name\", i, nextOffset) if err != nil { log.Println(\"ConsumePartition err:\", err) } defer pc.Close() for message := range pc.Messages() { value := string(message.Value) log.Printf(\"[Consumer] partitionid:%d; offset:%d, value:%s\\n\", message.Partition, message.Offset, value) //每次消费后都更新一次offset，这里更新的只是程序内存中的值，需要commit后才能提交到Kafka partitionOffsetManager.MarkOffset(message.Offset+1, \"modified metadata\") } } 1）创建偏移量管理器\noffsetManager, _ := sarama.NewOffsetManagerFromClient(\"myGroupID\", client) 2）创建对应分区的偏移量管理器\nKafka 中每个分区的偏移量是单独管理的\npartitionOffsetManager, _ := offsetManager.ManagePartition(topic, kafka.DefaultPartition) 3）记录偏移量\n这里记录的是下一条要取的消息，而不是取的最后一条消息，所以需要 +1\npartitionOffsetManager.MarkOffset(message.Offset+1, \"modified metadata\") 4）提交偏移量\nsarama 中默认会自动提交偏移量，但还是建议用 defer 在程序退出的时候手动提交一次。\ndefer offsetManager.Commit() 更多请看 ：https://www.lixueduan.com/posts/kafka/05-quick-start/#3-consumer-api\n","description":"","tags":null,"title":"Kafka","uri":"/posts/kafka/"},{"categories":null,"content":"什么是defer Go语言的一种用于注册延迟调用的机制，使得函数或语句可以在当前函数执行完毕后执行。\n为什么需要defer Go提供的语法糖，减少资源泄露的发生。\n如何使用defer 在创建资源语句的附近，使用defer语句释放资源。\ndefer语句的执行顺序 defer语句不会马上执行，而是会进入一个栈。函数return前，最先定义的defer语句最后执行。\ndefer函数定义时，对外部变量有两种方式：\n函数参数: 在defer定义时就把值传递给defer，并被cache起来； 闭包引用: 在defer函数真正调用时根据整个上下文确定参数当前的值 函数参数 1 2 3 4 5 6 7 8 9 10 11 12 13 func main() { var whatever [3]struct{} for i := range whatever { defer func(i int) { fmt.Println(i) }(i) } } $ go run main.go 2 1 0 闭包引用 1 2 3 4 5 6 7 8 9 10 11 12 13 14 func main(){ var whatever [3]struct{} for i := range whatever{ defer func(){ fmt.Println(i) }() } } $ go run main.go 2 2 2 defer的执行顺序和定义的顺序相反。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 package main import ( \"fmt\" ) type number int func (n number) print() { fmt.Println(n) } func (n *number) pprint() { fmt.Println(*n) } func main() { var n number defer n.print() defer n.pprint() defer func() { n.print() }() defer func() { n.pprint() }() n = 3 } $ go run main.go 3 //第四个defer语句是闭包，引用外部函数的n，最终结果是3 3 //第三个defer同上 3 //第二个defer语句中的n是引用，最终是3 0 //第一个 是对n直接求值，开始的时候n=0,所以最后是0 如果defer像前面介绍的那样简单，这个世界就完美了。但事情总是没这么简单，defer用得不好，会陷入泥潭。其他例子：\ndefer 关键字使用传值的方式传递参数时会进行预计算，导致不符合预期的结果；\n1 2 3 4 5 6 7 8 9 func main() { startedAt := time.Now() defer fmt.Println(time.Since(startedAt)) time.Sleep(time.Second) } $go run main.go 168.518µs 调用 defer 关键字会立刻拷贝函数中引用的外部参数，所以 time.Since(startedAt) 的结果不是在 main 函数退出之前计算的，而是在 defer 关键字调用时计算的，最终导致上述代码输出 0s。\n1 2 3 4 5 6 7 8 9 10 11 func main() { startedAt := time.Now() defer func() { fmt.Println(time.Since(startedAt)) }() time.Sleep(time.Second) } $ go run main.go 1.001001205s 拆解延迟语句 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 package main import ( \"fmt\" ) func f1() (r int) { t := 5 fmt.Println(\u0026t) fmt.Println(\u0026r) defer func() { t = t + 5 }() return t } func main() { fmt.Println(f1()) } $ go run main.go 5 必须深刻理解return t,这句编译之后，实际上生成三条指令：\n1 2 3 1. 返回值 r = t 2. 调用 defer函数，操作的是t 3. 空的return 1、3是return生成的指令，return并不是一条原子指令\n2 实际上并没有操作返回值r，操作的是t，可以打印出t, r的地址是不一样的。\n再看一个例子：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 package main import ( \"fmt\" ) func f() (r int) { fmt.Println(\u0026r) defer func(r int) { fmt.Println(\u0026r) r = r + 5 }(r) return 1 } func main() { fmt.Println(f()) } $ go run main.go 0xc0000160a8 0xc0000160c0 1 拆解：\n1 2 3 1. 返回值 r =1 2. 闭包，传参，打印两个r的地址，不是一个r。传值进去的r，是形参的一个复制值，不会影响实参r。 3. 空的return 确定延迟语句的参数 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 package main import ( \"errors\" \"fmt\" ) func e1() { var err error defer fmt.Println(err) err = errors.New(\"defer1 error\") return } func e2() { var err error defer func() { fmt.Println(err) }() err = errors.New(\"defer2 error\") return } func e3() { var err error defer func() { fmt.Println(err) }() err = errors.New(\"defer3 error\") return } func main() { e1() e2() e3() } //执行e1,e3时候，声明后，传入defer的是nil,然后被defer塞入栈中 //e2闭包使用的是指针，所以会打印defer2 error $ go run main.go \u003cnil\u003e defer2 error \u003cnil\u003e 延迟语句配合恢复语句 recover()函数只在defer的函数中直接调用才有效。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 package main import ( \"fmt\" \"time\" ) func main() { defer fmt.Println(\"defer main\") var user = \"\" go func() { defer func() { fmt.Println(\"defer caller\") if err := recover(); err != nil { fmt.Println(\"recover success err:\", err) } }() defer func() { defer func() { fmt.Println(\"defer here\") }() if user == \"\" { panic(\"should set user env\") } fmt.Println(\"after panic\") }() }() time.Sleep(1000) fmt.Println(\"end of main function\") } $ go run main.go end of main function defer main defer here defer caller recover success err: should set user env panic会停掉当前正在执行的程序，而不只是当前线程。在这之前，它会有序地执行完当前线程defer列表里的语句，其他协程里定义的defer语句不做保证。所以在defer里定义一个recover语句，防止程序直接挂掉，就可以起到try…catch的效果。\n其他 Go调度模型 三个实体：M(Machine)、P(Processor)、G(Goroutine)\nG: Go运行时对goroutine的描述，G中存放并发执行的代码入口地址、上下文、运行环境(关联的P和M)、运行栈等执行相关的信息。\nM: OS内核线程，是操作系统层面调度和执行的实体。直接关联一个内核级线程。\nP: 代表M和G所需要的资源，是对资源的一种抽象管理，P不是一段代码实体，而是一个管理的数据结构，P主要是降低M对G的复杂性，增加一个间接的控制层数据结构。P控制GO代码的并行度，它不是实体。\n闭包 闭包 = 函数 + 引用环境， 也称匿名函数，不能独立存在，但可以直接调用或赋值于某个变量。\n不太恰当的例子： 可以把闭包看成是一个类，闭包函数的一个调用就是实例化一个类。闭包在运行时可以有多个实例，它会将同一个作用域的变量和常量捕获，无论闭包在什么地方调用，都可以使用这些变量和常量。闭包捕获的变量和常量都是引用传递，不是值传递。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 package main import ( \"fmt\" ) func main() { var a = Accumulator() fmt.Printf(\"%d\\n\", a(1)) fmt.Printf(\"%d\\n\", a(10)) fmt.Printf(\"%d\\n\", a(100)) fmt.Println(\"--------------------------------\") var b = Accumulator() fmt.Printf(\"%d\\n\", b(1)) fmt.Printf(\"%d\\n\", b(10)) fmt.Printf(\"%d\\n\", b(100)) } func Accumulator() func(int) int { var x int return func(delta int) int { fmt.Printf(\"(%+v, %+v) - \", \u0026x, x) x += delta return x } } 闭包已用了x变量，a,b可看作2个不同的实例，实例之间互不影响，实例内部，x变量是同一个地址，因此具有\"累加效应\"\n","description":"","tags":null,"title":"GO Defer","uri":"/posts/go-defer/"},{"categories":null,"content":"逃逸分析 “Quality is never an accident; it is always the result of intelligent effort.” — John Ruskin.\n逃逸分析是什么 Go编译器的一个阶段，对代码进行逃逸分析，确定其中变量的内存分配位置(栈、堆)，把变量合理地分配到它该去的地方。\n逃逸是什么？当一个对象的指针被多个方法或线程引用时，那么这个指针就会发生逃逸。如果一个函数返回对一个变量的引用，那么这个变量就会发生逃逸。\n逃逸分析作用 栈：分配速度快，只需通过PUSH指令，函数return后可自动释放 堆：需要找到合适大小的内存块，易形成内存碎片，通过垃圾回收才能释放 通过逃逸分析，可以把一些不需要分配到堆上的变量直接分配到栈上，减轻堆内存分配的开销。GC会定期停止并收集未使用的对象，这也减轻了GC的压力，提高程序的运行速度。\n如何确定是否发生逃逸 例子如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 package main import ( \"fmt\" ) func foo() *int { t := 3 return \u0026t } func main() { x := foo() fmt.Println(*x) } 使用go build -gcflags '-m -l' xx.go查看Go编译过程中变量是否发生逃逸。-gcflags参数用于弃用编译器支持的额外标志。如，-m用于输出编译器的优化细节(包括使用逃逸分析这种优化)，相反可以使用-N来关闭编译器优化；而-l则用于禁用foo函数的内联优化，防止逃逸被编译器通过内联彻底地抹除。\n1 2 3 4 $ go build -gcflags '-m -l' main.go ./escapeAnalysis.go:8:2: moved to heap: t ./escapeAnalysis.go:14:13: ... argument does not escape ./escapeAnalysis.go:14:14: *x escapes to heap 可以看到t被移动到堆上，发生了逃逸，*x也发生了逃逸，因为Println()函数的参数类型为interface{}，编译期间很难确定其参数的具体类型，也会发生逃逸。\n使用反汇编命令也可以看出变量是否发生逃逸。执行命令：go tool compile -S main.go\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 \"\".foo STEXT size=79 args=0x8 locals=0x18 funcid=0x0 0x0000 00000 (escapeAnalysis.go:7) TEXT \"\".foo(SB), ABIInternal, $24-8 0x0000 00000 (escapeAnalysis.go:7) MOVQ (TLS), CX 0x0009 00009 (escapeAnalysis.go:7) CMPQ SP, 16(CX) 0x000d 00013 (escapeAnalysis.go:7) PCDATA $0, $-2 0x000d 00013 (escapeAnalysis.go:7) JLS 72 0x000f 00015 (escapeAnalysis.go:7) PCDATA $0, $-1 0x000f 00015 (escapeAnalysis.go:7) SUBQ $24, SP 0x0013 00019 (escapeAnalysis.go:7) MOVQ BP, 16(SP) 0x0018 00024 (escapeAnalysis.go:7) LEAQ 16(SP), BP 0x001d 00029 (escapeAnalysis.go:7) FUNCDATA $0, gclocals·2a5305abe05176240e61b8620e19a815(SB) 0x001d 00029 (escapeAnalysis.go:7) FUNCDATA $1, gclocals·33cdeccccebe80329f1fdbee7f5874cb(SB) 0x001d 00029 (escapeAnalysis.go:8) LEAQ type.int(SB), AX 0x0024 00036 (escapeAnalysis.go:8) MOVQ AX, (SP) 0x0028 00040 (escapeAnalysis.go:8) PCDATA $1, $0 0x0028 00040 (escapeAnalysis.go:8) CALL runtime.newobject(SB) 0x002d 00045 (escapeAnalysis.go:8) MOVQ 8(SP), AX 0x0032 00050 (escapeAnalysis.go:8) MOVQ $3, (AX) 0x0039 00057 (escapeAnalysis.go:9) MOVQ AX, \"\".~r0+32(SP) 0x003e 00062 (escapeAnalysis.go:9) MOVQ 16(SP), BP 0x0043 00067 (escapeAnalysis.go:9) ADDQ $24, SP 0x0047 00071 (escapeAnalysis.go:9) RET 0x0048 00072 (escapeAnalysis.go:9) NOP 0x0048 00072 (escapeAnalysis.go:7) PCDATA $1, $-1 0x0048 00072 (escapeAnalysis.go:7) PCDATA $0, $-2 0x0048 00072 (escapeAnalysis.go:7) CALL runtime.morestack_noctxt(SB) 0x004d 00077 (escapeAnalysis.go:7) PCDATA $0, $-1 0x004d 00077 (escapeAnalysis.go:7) JMP 0 这是部分结果，其中有使用runtime.newobject()函数，它的作用是在堆上分配一块内存，从而说明变量发生了逃逸。\nGo与C/C++中的堆栈概念的区别 C/C++中的堆栈是操作系统级别的概念，它通过编译器所在的环境来决定。\n栈：指的是程序运行时自动获得的一小块内存，函数调用消耗的栈的大小，会在编译期间由编译器决定。这块内存用于保存局部变量或者保存函数调用栈。（1MB） 堆：每当程序通过系统调用向操作系统申请内存时，会将所需的空间从维护的堆内存地址空间中分配出去，而在归还是将归还的内存合并到所维护的地址空间中。（1GB） Go语言中的堆栈与C/C++中的有较大区别。Go语言中的堆栈都指的是Go运行时向操作系统申请的堆内存，被全部用于Go的运行时，维护运行时各个组件的协调。调度器、垃圾回收、系统调用等。所以从理论上来说，相较于只有1MB的C/C++中的栈而言，Go可以拥有1GB的栈内存。\nGo指针不能算术运算 Go语言运行时为了防止内存碎片化，会适当对整个栈进行深拷贝，将其整个复制到另一块内存（这个过程对用户态的代码是不可见的），所以在运行过程中无法确定运算前后指针所指向的地址内容是否被运行时移动。也正是这个原因，指针的算术运算不再能生效。\n","description":"","tags":null,"title":"GO Escape Analysis","uri":"/posts/go-escape-analysis/"}]